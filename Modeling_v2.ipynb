{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrongly used the submission example file for the modeling, going to start things clean over again\n",
    "#setting up libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess (source_df):\n",
    "    \n",
    "    #first we drop the unwanted columns\n",
    "    source_df_droped = source_df.drop(['PassengerId', 'Name','Ticket','Cabin'], axis=1)\n",
    "\n",
    "    \n",
    "    #then we impute Age\n",
    "    age_imputer = SimpleImputer()\n",
    "    source_df_droped_justAge = source_df_droped[['Age']]\n",
    "    imputed_Age = pd.DataFrame(age_imputer.fit_transform(source_df_droped_justAge))\n",
    "\n",
    "    #impute removes column name and index, adding it back\n",
    "    imputed_Age.columns = source_df_droped_justAge.columns\n",
    "    imputed_Age.index = source_df_droped.index\n",
    "\n",
    "    #adding imputed data to the source df\n",
    "    source_df_imputed = source_df_droped.drop('Age', axis=1).join(imputed_Age)\n",
    "    \n",
    "    #lesson learned, I should impute data before droping rows, and deleting rows is not a good idea, let's impute with most common values\n",
    "    source_df_imputed[\"Embarked\"] = source_df_imputed[\"Embarked\"].fillna(source_df_imputed[\"Embarked\"].value_counts().index[0])\n",
    "    source_df_imputed[\"Fare\"] = source_df_imputed[\"Fare\"].fillna(source_df_imputed[\"Fare\"].value_counts().index[0])\n",
    "    \n",
    "    #next we apply One-Hot\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    OH_source_df_imputed_col = OH_en.fit_transform(source_df_imputed[['Sex','Embarked']])\n",
    "    OH_source_df_imputed_col = pd.DataFrame(OH_source_df_imputed_col)\n",
    "    \n",
    "    #alining index \n",
    "    OH_source_df_imputed_col.index = source_df_imputed[['Sex','Embarked']].index\n",
    "    #alining columns\n",
    "    OH_source_df_imputed_col.columns = OH_en.get_feature_names(['Sex','Embarked'])\n",
    "    processed_df = source_df_imputed.drop(['Sex','Embarked'], axis=1).join(OH_source_df_imputed_col)\n",
    "\n",
    "    \n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kv_feature (train_set, test_set,k_value):\n",
    "    f_cols = train_set.columns.drop('Survived')\n",
    "    #we have 10 features, let's keep five to avoid overfitting\n",
    "    selector = SelectKBest(f_classif, k=k_value)\n",
    "    X_new = selector.fit_transform(train_set[f_cols], train_set['Survived'])\n",
    "    \n",
    "    #transforming back to the original df format\n",
    "    selected_features = pd.DataFrame(selector.inverse_transform(X_new), \n",
    "                                 index=train_set.index, \n",
    "                                 columns=f_cols)\n",
    "    selected_columns = selected_features.columns[selected_features.var() != 0]\n",
    "    \n",
    "    return train_set[selected_columns], train_set['Survived'], test_set[selected_columns], test_set['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_one_feature (train_set, test_set):\n",
    "    f_cols = train_set.columns.drop('Survived')\n",
    "    X, y = train_set[f_cols], train_set['Survived']\n",
    "\n",
    "    # Setting up the model\n",
    "    logistic = LogisticRegression(C=1, penalty=\"l1\", solver='liblinear', random_state=7).fit(X, y)\n",
    "    model = SelectFromModel(logistic, prefit=True)\n",
    "    \n",
    "    #applying the model\n",
    "    X_new = model.transform(X)\n",
    "    \n",
    "    #transforming back to the original df format\n",
    "    selected_features = pd.DataFrame(model.inverse_transform(X_new), \n",
    "                                 index=X.index,\n",
    "                                 columns=X.columns)\n",
    "    selected_columns = selected_features.columns[selected_features.var() != 0]\n",
    "    \n",
    "    return train_set[selected_columns], train_set['Survived'], test_set[selected_columns], test_set['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_cal (pred_data, result):\n",
    "    comp = pred_data == result\n",
    "    #need to convert to list to use count(True)\n",
    "    num_r = comp.tolist().count(True)\n",
    "    acc_p = num_r/len(comp.tolist())\n",
    "    return acc_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt (X_train, y_train, X_test, y_test):\n",
    "    dt_model = DecisionTreeClassifier(random_state=1)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    score = acc_cal(dt_model.predict(X_test), y_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the Random Forest Model\n",
    "def rf (X_train, y_train, X_test, y_test):\n",
    "    forest_model = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "    forest_model.fit(X_train, y_train)\n",
    "    pred = forest_model.predict(X_test)\n",
    "    score = acc_cal(pred, y_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb (X_train, y_train, X_test, y_test):\n",
    "    xgb_model = XGBRFClassifier(n_estimators=10000)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    pred = xgb_model.predict(X_test)\n",
    "    score = acc_cal(pred, y_test)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_tuned (X_train, y_train, X_test, y_test):\n",
    "    xgb_model = XGBRFClassifier(n_estimators=10000, learning_rate=0.05)\n",
    "    xgb_model.fit(X_train, y_train, \n",
    "             early_stopping_rounds=5, \n",
    "             eval_set=[(X_test, y_test)], \n",
    "             verbose=False)\n",
    "    pred = xgb_model.predict(X_test)\n",
    "    score = acc_cal(pred, y_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    #run decision tree model\n",
    "    score_dt = dt(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    #run the Random Forest Model\n",
    "    score_rf = rf(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    #run the XGB tuned model\n",
    "    score_xgb = xgb_tuned(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    \n",
    "    print(score_dt)\n",
    "    print(score_rf)\n",
    "    print(score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_test_split(train_data, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean, val_clean = data_preprocess(train_dataset), data_preprocess(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Age           0\n",
       "Sex_female    0\n",
       "Sex_male      0\n",
       "Embarked_C    0\n",
       "Embarked_Q    0\n",
       "Embarked_S    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24.15</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>70.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>73.50</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.70</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>29.77331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  SibSp  Parch   Fare       Age  Sex_female  Sex_male  \\\n",
       "419         0       3      0      2  24.15  10.00000         1.0       0.0   \n",
       "116         0       3      0      0   7.75  70.50000         0.0       1.0   \n",
       "120         0       2      2      0  73.50  21.00000         0.0       1.0   \n",
       "10          1       3      1      1  16.70   4.00000         1.0       0.0   \n",
       "121         0       3      0      0   8.05  29.77331         0.0       1.0   \n",
       "\n",
       "     Embarked_C  Embarked_Q  Embarked_S  \n",
       "419         0.0         0.0         1.0  \n",
       "116         0.0         1.0         0.0  \n",
       "120         0.0         0.0         1.0  \n",
       "10          0.0         0.0         1.0  \n",
       "121         0.0         0.0         1.0  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7932960893854749\n",
      "0.776536312849162\n",
      "0.776536312849162\n"
     ]
    }
   ],
   "source": [
    "X_kv_train, y_kv_train, X_kv_test, y_kv_test = kv_feature(train_clean, val_clean, 4)\n",
    "run_models(X_kv_train, y_kv_train, X_kv_test, y_kv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7094972067039106\n",
      "0.7877094972067039\n",
      "0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "X_L_one_train, y_L_one_train, X_L_one_test, y_L_one_test = L_one_feature(train_clean, val_clean)\n",
    "run_models(X_L_one_train, y_L_one_train, X_L_one_test, y_L_one_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7150837988826816\n",
      "0.7877094972067039\n",
      "0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "run_models(train_clean.drop('Survived', axis = 1), train_clean.Survived, val_clean.drop('Survived', axis = 1), val_clean.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Age</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Cabin</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Sex</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SibSp</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Ticket</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>90</td>\n",
       "      <td>270</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>97</td>\n",
       "      <td>372</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>372</td>\n",
       "      <td>80</td>\n",
       "      <td>97</td>\n",
       "      <td>372</td>\n",
       "      <td>80</td>\n",
       "      <td>97</td>\n",
       "      <td>372</td>\n",
       "      <td>80</td>\n",
       "      <td>97</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>117</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>134</td>\n",
       "      <td>87</td>\n",
       "      <td>119</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>136</td>\n",
       "      <td>87</td>\n",
       "      <td>119</td>\n",
       "      <td>136</td>\n",
       "      <td>87</td>\n",
       "      <td>119</td>\n",
       "      <td>136</td>\n",
       "      <td>87</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age          Cabin        Embarked          Fare  ... PassengerId  \\\n",
       "Pclass      1   2    3     1   2  3        1   2    3    1  ...           3   \n",
       "Survived                                                    ...               \n",
       "0          64  90  270    59   3  6       80  97  372   80  ...         372   \n",
       "1         122  83   85   117  13  6      134  87  119  136  ...         119   \n",
       "\n",
       "          Sex          SibSp          Ticket           \n",
       "Pclass      1   2    3     1   2    3      1   2    3  \n",
       "Survived                                               \n",
       "0          80  97  372    80  97  372     80  97  372  \n",
       "1         136  87  119   136  87  119    136  87  119  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(train_data, index = 'Survived', columns = 'Pclass', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
